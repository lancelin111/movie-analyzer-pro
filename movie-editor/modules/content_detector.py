"""
å†…å®¹æ£€æµ‹æ¨¡å—
è‡ªåŠ¨è¯†åˆ«ç‰‡å¤´ã€ç‰‡å°¾ã€å¹¿å‘Šç­‰éæ­£ç‰‡å†…å®¹
"""

import cv2
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import subprocess
import json

class ContentDetector:
    """æ£€æµ‹è§†é¢‘ä¸­çš„ç‰‡å¤´ã€ç‰‡å°¾ã€å¹¿å‘Šç­‰å†…å®¹"""
    
    def __init__(self, video_path: str):
        """åˆå§‹åŒ–å†…å®¹æ£€æµ‹å™¨"""
        self.video_path = Path(video_path)
        self.cap = None
        self.fps = 0
        self.frame_count = 0
        self.width = 0
        self.height = 0
        
    def detect_content_boundaries(self, sample_duration: int = 600) -> Dict:
        """
        æ£€æµ‹å†…å®¹è¾¹ç•Œï¼ˆç‰‡å¤´ã€ç‰‡å°¾ã€å¹¿å‘Šï¼‰
        
        Args:
            sample_duration: é‡‡æ ·æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤åˆ†æå‰10åˆ†é’Ÿ
            
        Returns:
            åŒ…å«ç‰‡å¤´ã€ç‰‡å°¾ã€æ­£ç‰‡æ—¶é—´æ®µçš„å­—å…¸
        """
        print("\nğŸ” æ£€æµ‹è§†é¢‘å†…å®¹ç»“æ„...")
        
        # æ‰“å¼€è§†é¢‘
        self.cap = cv2.VideoCapture(str(self.video_path))
        self.fps = self.cap.get(cv2.CAP_PROP_FPS)
        self.frame_count = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_duration = self.frame_count / self.fps
        
        print(f"  â€¢ è§†é¢‘æ€»æ—¶é•¿: {total_duration/60:.1f}åˆ†é’Ÿ")
        
        # 1. æ£€æµ‹ç‰‡å¤´
        intro_end = self._detect_intro()
        
        # 2. æ£€æµ‹ç‰‡å°¾
        outro_start = self._detect_outro()
        
        # 3. æ£€æµ‹å¹¿å‘Š/ä¸­æ–­
        ad_segments = self._detect_ads(intro_end, outro_start, sample_duration)
        
        # 4. æ£€æµ‹é»‘åœºï¼ˆå¸¸è§çš„åˆ†æ®µæ ‡å¿—ï¼‰
        black_segments = self._detect_black_frames(intro_end, outro_start)
        
        self.cap.release()
        
        # æ•´ç†ç»“æœ
        result = {
            'total_duration': total_duration,
            'intro': {
                'start': 0,
                'end': intro_end,
                'duration': intro_end
            },
            'outro': {
                'start': outro_start,
                'end': total_duration,
                'duration': total_duration - outro_start
            },
            'main_content': {
                'start': intro_end,
                'end': outro_start,
                'duration': outro_start - intro_end
            },
            'ads': ad_segments,
            'black_frames': black_segments
        }
        
        # æ‰“å°æ£€æµ‹ç»“æœ
        print(f"\nâœ… å†…å®¹ç»“æ„æ£€æµ‹å®Œæˆ:")
        print(f"  â€¢ ç‰‡å¤´: 0:00 - {self._format_time(intro_end)}")
        print(f"  â€¢ æ­£ç‰‡: {self._format_time(intro_end)} - {self._format_time(outro_start)}")
        print(f"  â€¢ ç‰‡å°¾: {self._format_time(outro_start)} - {self._format_time(total_duration)}")
        
        if ad_segments:
            print(f"  â€¢ æ£€æµ‹åˆ° {len(ad_segments)} ä¸ªå¹¿å‘Šæ®µ")
        
        return result
    
    def _detect_intro(self) -> float:
        """
        æ£€æµ‹ç‰‡å¤´ç»“æŸæ—¶é—´
        é€šè¿‡ä»¥ä¸‹ç‰¹å¾åˆ¤æ–­ï¼š
        1. éŸ³é¢‘çªå˜ï¼ˆèƒŒæ™¯éŸ³ä¹ç»“æŸï¼‰
        2. åœºæ™¯å¿«é€Ÿåˆ‡æ¢ç»“æŸ
        3. æ–‡å­—/LOGOæ¶ˆå¤±
        4. é»‘åœºè¿‡æ¸¡
        """
        print("  ğŸ¬ æ£€æµ‹ç‰‡å¤´...")
        
        # åˆ†æå‰3åˆ†é’Ÿ
        max_intro_duration = min(180, self.frame_count / self.fps)
        
        # ç‰¹å¾æ£€æµ‹
        features = []
        
        # 1. åœºæ™¯åˆ‡æ¢é¢‘ç‡åˆ†æ
        scene_changes = self._analyze_scene_change_frequency(0, max_intro_duration)
        
        # 2. æ–‡å­—å¯†åº¦åˆ†æï¼ˆç‰‡å¤´é€šå¸¸æœ‰æ¼”èŒå‘˜è¡¨ï¼‰
        text_density = self._analyze_text_density(0, max_intro_duration)
        
        # 3. éŸ³é¢‘åˆ†æï¼ˆå¦‚æœå¯èƒ½ï¼‰
        audio_changes = self._analyze_audio_changes(0, max_intro_duration)
        
        # ç»¼åˆåˆ¤æ–­ç‰‡å¤´ç»“æŸç‚¹
        intro_end = 0
        
        # æŸ¥æ‰¾åœºæ™¯åˆ‡æ¢é¢‘ç‡é™ä½çš„ç‚¹
        for i in range(1, len(scene_changes)):
            if scene_changes[i] < scene_changes[i-1] * 0.5:  # åˆ‡æ¢é¢‘ç‡é™ä½50%
                intro_end = i * 10  # æ¯10ç§’ä¸€ä¸ªé‡‡æ ·ç‚¹
                break
        
        # å¦‚æœæ²¡æ‰¾åˆ°æ˜æ˜¾çš„ç‰‡å¤´ï¼Œé»˜è®¤30ç§’
        if intro_end == 0:
            intro_end = min(30, max_intro_duration)
        
        return intro_end
    
    def _detect_outro(self) -> float:
        """
        æ£€æµ‹ç‰‡å°¾å¼€å§‹æ—¶é—´
        é€šè¿‡ä»¥ä¸‹ç‰¹å¾åˆ¤æ–­ï¼š
        1. æ»šåŠ¨å­—å¹•å¼€å§‹
        2. é»‘åœº
        3. éŸ³é¢‘æ·¡å‡º
        """
        print("  ğŸ¬ æ£€æµ‹ç‰‡å°¾...")
        
        total_duration = self.frame_count / self.fps
        
        # åˆ†ææœ€å5åˆ†é’Ÿ
        check_duration = min(300, total_duration)
        outro_start = total_duration - check_duration
        
        # ä»åå‘å‰æ£€æŸ¥
        for t in range(int(total_duration - 30), int(outro_start), -10):
            # æ£€æŸ¥æ˜¯å¦æœ‰æ»šåŠ¨å­—å¹•
            if self._has_rolling_credits(t):
                return t
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é»‘åœº
            if self._is_black_frame(t):
                # ç¡®è®¤åç»­éƒ½æ˜¯é»‘åœºæˆ–å­—å¹•
                if self._is_ending_content(t, total_duration):
                    return t
        
        # é»˜è®¤æœ€å1åˆ†é’Ÿä¸ºç‰‡å°¾
        return max(total_duration - 60, total_duration * 0.95)
    
    def _detect_ads(self, intro_end: float, outro_start: float, 
                   sample_duration: int) -> List[Dict]:
        """æ£€æµ‹å¹¿å‘Šæ®µè½"""
        ads = []
        
        # å¹¿å‘Šé€šå¸¸æœ‰ä»¥ä¸‹ç‰¹å¾ï¼š
        # 1. çªç„¶çš„éŸ³é‡å˜åŒ–
        # 2. ç”»é¢é£æ ¼çªå˜
        # 3. å›ºå®šçš„æ—¶é•¿ï¼ˆ15ç§’ã€30ç§’ç­‰ï¼‰
        
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œä¸»è¦é€šè¿‡åœºæ™¯çªå˜æ£€æµ‹
        check_end = min(intro_end + sample_duration, outro_start)
        
        # TODO: å®ç°æ›´å¤æ‚çš„å¹¿å‘Šæ£€æµ‹é€»è¾‘
        
        return ads
    
    def _detect_black_frames(self, start: float, end: float) -> List[Dict]:
        """æ£€æµ‹é»‘åœºæ®µè½"""
        black_segments = []
        
        sample_interval = 5  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
        current_black_start = None
        
        for t in range(int(start), int(end), sample_interval):
            if self._is_black_frame(t):
                if current_black_start is None:
                    current_black_start = t
            else:
                if current_black_start is not None:
                    # é»‘åœºç»“æŸ
                    if t - current_black_start >= 2:  # è‡³å°‘2ç§’çš„é»‘åœºæ‰è®°å½•
                        black_segments.append({
                            'start': current_black_start,
                            'end': t,
                            'duration': t - current_black_start
                        })
                    current_black_start = None
        
        return black_segments
    
    def _analyze_scene_change_frequency(self, start: float, end: float) -> List[float]:
        """åˆ†æåœºæ™¯åˆ‡æ¢é¢‘ç‡"""
        frequencies = []
        window_size = 10  # 10ç§’çª—å£
        
        for t in range(int(start), int(end), window_size):
            changes = self._count_scene_changes(t, min(t + window_size, end))
            frequencies.append(changes / window_size)
        
        return frequencies
    
    def _count_scene_changes(self, start: float, end: float) -> int:
        """ç»Ÿè®¡æ—¶é—´æ®µå†…çš„åœºæ™¯åˆ‡æ¢æ¬¡æ•°"""
        changes = 0
        
        # æ¯ç§’é‡‡æ ·ä¸€å¸§
        start_frame = int(start * self.fps)
        end_frame = int(end * self.fps)
        
        prev_frame = None
        for frame_idx in range(start_frame, end_frame, int(self.fps)):
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = self.cap.read()
            
            if not ret:
                break
            
            if prev_frame is not None:
                # è®¡ç®—å¸§å·®å¼‚
                diff = cv2.absdiff(frame, prev_frame)
                mean_diff = np.mean(diff)
                
                if mean_diff > 30:  # é˜ˆå€¼
                    changes += 1
            
            prev_frame = frame
        
        return changes
    
    def _analyze_text_density(self, start: float, end: float) -> List[float]:
        """åˆ†ææ–‡å­—å¯†åº¦ï¼ˆç‰‡å¤´é€šå¸¸æœ‰æ¼”èŒå‘˜è¡¨ï¼‰"""
        densities = []
        
        # ç®€åŒ–ï¼šé€šè¿‡è¾¹ç¼˜æ£€æµ‹ä¼°ç®—æ–‡å­—åŒºåŸŸ
        window_size = 10
        
        for t in range(int(start), int(end), window_size):
            frame_idx = int(t * self.fps)
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = self.cap.read()
            
            if ret:
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                edges = cv2.Canny(gray, 100, 200)
                density = np.sum(edges > 0) / edges.size
                densities.append(density)
            else:
                densities.append(0)
        
        return densities
    
    def _analyze_audio_changes(self, start: float, end: float) -> List[float]:
        """åˆ†æéŸ³é¢‘å˜åŒ–ï¼ˆéœ€è¦ffmpegï¼‰"""
        # TODO: å®ç°éŸ³é¢‘åˆ†æ
        return []
    
    def _has_rolling_credits(self, time: float) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æ»šåŠ¨å­—å¹•"""
        # æ£€æŸ¥è¿ç»­å‡ å¸§ï¼Œçœ‹æ˜¯å¦æœ‰å‚ç›´ç§»åŠ¨çš„æ–‡å­—
        frames_to_check = 5
        frame_idx = int(time * self.fps)
        
        frames = []
        for i in range(frames_to_check):
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx + i * int(self.fps/5))
            ret, frame = self.cap.read()
            if ret:
                # åªä¿ç•™åº•éƒ¨åŒºåŸŸï¼ˆå­—å¹•é€šå¸¸åœ¨è¿™é‡Œï¼‰
                bottom = frame[int(self.height * 0.5):, :]
                gray = cv2.cvtColor(bottom, cv2.COLOR_BGR2GRAY)
                frames.append(gray)
        
        if len(frames) < 2:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å‚ç›´ç§»åŠ¨
        for i in range(1, len(frames)):
            # è®¡ç®—å…‰æµæˆ–æ¨¡æ¿åŒ¹é…æ¥æ£€æµ‹å‚ç›´ç§»åŠ¨
            # è¿™é‡Œç®€åŒ–ï¼šæ¯”è¾ƒå¸§å·®å¼‚
            diff = cv2.absdiff(frames[i], frames[i-1])
            if np.mean(diff) > 10:  # æœ‰æ˜æ˜¾å˜åŒ–
                return True
        
        return False
    
    def _is_black_frame(self, time: float) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯é»‘åœº"""
        frame_idx = int(time * self.fps)
        self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = self.cap.read()
        
        if not ret:
            return False
        
        # è®¡ç®—å¹³å‡äº®åº¦
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        mean_brightness = np.mean(gray)
        
        return mean_brightness < 20  # é˜ˆå€¼
    
    def _is_ending_content(self, start: float, end: float) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯ç»“å°¾å†…å®¹ï¼ˆé»‘åœºæˆ–å­—å¹•ï¼‰"""
        # é‡‡æ ·å‡ ä¸ªç‚¹æ£€æŸ¥
        for t in range(int(start), int(end), 10):
            if not self._is_black_frame(t) and not self._has_rolling_credits(t):
                return False
        return True
    
    def _format_time(self, seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes}:{secs:02d}"
    
    def extract_main_content(self, output_path: str = None) -> str:
        """
        æå–ä¸»è¦å†…å®¹ï¼ˆå»é™¤ç‰‡å¤´ç‰‡å°¾ï¼‰
        
        Args:
            output_path: è¾“å‡ºè·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # æ£€æµ‹å†…å®¹è¾¹ç•Œ
        boundaries = self.detect_content_boundaries()
        
        # ç”Ÿæˆè¾“å‡ºè·¯å¾„
        if output_path is None:
            output_path = self.video_path.stem + "_main_content" + self.video_path.suffix
        
        output_path = Path(output_path)
        
        print(f"\nâœ‚ï¸ æå–ä¸»è¦å†…å®¹...")
        print(f"  â€¢ å¼€å§‹: {self._format_time(boundaries['main_content']['start'])}")
        print(f"  â€¢ ç»“æŸ: {self._format_time(boundaries['main_content']['end'])}")
        print(f"  â€¢ æ—¶é•¿: {boundaries['main_content']['duration']/60:.1f}åˆ†é’Ÿ")
        
        # ä½¿ç”¨ffmpegå‰ªåˆ‡è§†é¢‘
        cmd = [
            'ffmpeg', '-y',
            '-i', str(self.video_path),
            '-ss', str(boundaries['main_content']['start']),
            '-to', str(boundaries['main_content']['end']),
            '-c', 'copy',  # ç›´æ¥å¤åˆ¶ï¼Œä¸é‡æ–°ç¼–ç 
            str(output_path)
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            print(f"  âœ… ä¸»è¦å†…å®¹å·²ä¿å­˜: {output_path}")
            return str(output_path)
        else:
            print(f"  âŒ æå–å¤±è´¥: {result.stderr}")
            return None


def test_content_detection(video_path: str):
    """æµ‹è¯•å†…å®¹æ£€æµ‹"""
    detector = ContentDetector(video_path)
    
    # æ£€æµ‹å†…å®¹è¾¹ç•Œ
    boundaries = detector.detect_content_boundaries()
    
    # ä¿å­˜æ£€æµ‹ç»“æœ
    output_dir = Path("output/content_detection")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    result_path = output_dir / "boundaries.json"
    with open(result_path, 'w', encoding='utf-8') as f:
        json.dump(boundaries, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“ æ£€æµ‹ç»“æœå·²ä¿å­˜: {result_path}")
    
    # æå–ä¸»è¦å†…å®¹
    main_content_path = output_dir / "main_content.mp4"
    detector.extract_main_content(str(main_content_path))
    
    return boundaries


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        video_path = sys.argv[1]
    else:
        video_path = "/Users/linguangjie/movie-editor/ç”Ÿä¸‡ç‰©-01.mp4"
    
    test_content_detection(video_path)